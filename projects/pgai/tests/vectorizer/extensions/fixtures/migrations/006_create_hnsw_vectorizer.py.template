"""HNSW vectorizer migration template.

Revision ID: {revision_id}
Revises: {revises}
Create Date: {create_date}
"""
from alembic import op
from sqlalchemy import Column, Integer, String, Text, Float
from datetime import timedelta
from pgai.vectorizer.configuration import (
    OpenAIConfig,
    CharacterTextSplitterConfig,
    HNSWIndexingConfig,
    PythonTemplateConfig,
    CreateVectorizerParams,
    TimescaleSchedulingConfig
)
from sqlalchemy import text

# revision identifiers, used by Alembic
revision = '{revision_id}'
down_revision = {down_revision}
branch_labels = None
depends_on = None


def upgrade() -> None:
    # Create a product_descriptions table
    op.create_table(
        'product_descriptions',
        Column('id', Integer, primary_key=True),
        Column('name', String(100), nullable=False),
        Column('description', Text, nullable=False),
        Column('category', String(50), nullable=False),
        Column('price', Float, nullable=False),
        Column('features', Text),  # JSON array of features
        schema='public'
    )

    # Create vectorizer with configuration classes
    op.create_vectorizer(
        source_table='public.product_descriptions',
        embedding=OpenAIConfig(
            model='text-embedding-3-small',
            dimensions=768,
            api_key_name='TEST_OPENAI_KEY'
        ),
        chunking=CharacterTextSplitterConfig(
            chunk_column='description',
            chunk_size=200,
            chunk_overlap=25,
            separator=' ',  # Using default separator since none was specified in original
            is_separator_regex=False
        ),
        indexing=HNSWIndexingConfig(
            min_rows=50000,
            opclass='vector_l1_ops',
            m=16,
            ef_construction=64,
            create_when_queue_empty=True
        ),
        formatting=PythonTemplateConfig(
            template='Product: $name\nCategory: $category\nPrice: $price\nFeatures: $features\nDescription: $chunk'
        ),
        scheduling=TimescaleSchedulingConfig(
            interval=timedelta(minutes=5),
            retention_policy='1d',
            fixed_schedule=False
        ),
    )


def downgrade() -> None:
    connection = op.get_bind()
    # Look up the vectorizer ID
    result = connection.execute(
        text("SELECT id FROM ai.vectorizer WHERE source_table = 'public.product_descriptions'")
    ).scalar()
    
    if result is not None:
        print("Found vectorizer with ID:" + result)
        op.drop_vectorizer(result, drop_all=True)
    else:
        print("No vectorizer found!")
    
    # Drop the product_descriptions table
    op.drop_table('product_descriptions', schema='public')